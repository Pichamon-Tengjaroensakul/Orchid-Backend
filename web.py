# -*- coding: utf-8 -*-
"""web.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TN_hr5quR-jJ2BfiK87Xm5Wk9E9ofT8P
"""

from fastapi import FastAPI, File, UploadFile, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from typing import List
import uvicorn
import pandas as pd
import numpy as np
import joblib
import os
import re
import io

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ==========================================
# 1. โหลดโมเดล
# ==========================================
MODEL_FILENAME = 'orchid_decision_tree_v1.pkl'
MODEL_PATH = os.path.join(os.path.dirname(__file__), MODEL_FILENAME)
model_data = None

try:
    if os.path.exists(MODEL_PATH):
        model_data = joblib.load(MODEL_PATH)
        print(f"✅ โหลดโมเดลสำเร็จ: {MODEL_FILENAME}")
    else:
        print(f"❌ ไม่พบไฟล์โมเดล: {MODEL_PATH}")
except Exception as e:
    print(f"❌ Error loading model: {e}")

# ==========================================
# 2. ฟังก์ชันคำนวณ Feature
# ==========================================
def extract_peak_features(t, f):
    try:
        mask = ~np.isnan(t) & ~np.isnan(f)
        t, f = np.asarray(t[mask]), np.asarray(f[mask])
        if len(t) < 3: return np.nan, np.nan, np.nan, np.nan

        sort_idx = np.argsort(t)
        t, f = t[sort_idx], f[sort_idx]

        peak_idx = np.argmax(f)
        F_peak = float(f[peak_idx])
        T_peak = float(t[peak_idx])

        if hasattr(np, 'trapezoid'): area = float(np.trapezoid(f, x=t))
        else: area = float(np.trapz(f, t))

        half = F_peak / 2.0
        above_half = np.where(f >= half)[0]
        if len(above_half) >= 2:
            width = float(t[above_half[-1]] - t[above_half[0]])
        else: width = np.nan

        return T_peak, F_peak, width, area
    except:
        return np.nan, np.nan, np.nan, np.nan

# ==========================================
# 3. API Endpoints
# ==========================================
@app.get("/")
def home():
    status = "พร้อมใช้งาน (Excel & CSV Supported)" if model_data else "ไม่พบโมเดล"
    return {"message": f"Orchid AI Backend: {status}"}

@app.post("/predict")
async def predict(files: List[UploadFile] = File(...)):
    if not model_data:
        raise HTTPException(status_code=500, detail="Model file not found on server.")

    all_results = []

    try:
        for file in files:
            contents = await file.read()
            filename = file.filename.lower()

            # ✅ เช็คสกุลไฟล์แล้วเลือกวิธีอ่านให้ถูก
            try:
                if filename.endswith('.csv'):
                    df = pd.read_csv(io.BytesIO(contents))
                else:
                    # รองรับทั้ง .xlsx และ .xls
                    df = pd.read_excel(io.BytesIO(contents))
            except Exception as read_err:
                print(f"❌ อ่านไฟล์ {filename} ไม่ได้: {read_err}")
                continue # ข้ามไฟล์ที่เสียไป

            columns = df.columns.tolist()
            processed_pairs = set()

            def process_and_predict(t_arr, f_arr, sample_name):
                T_peak, F_peak, width, area = extract_peak_features(t_arr, f_arr)
                if not np.isnan(T_peak):
                    features_df = pd.DataFrame([[T_peak, F_peak, width, area]],
                                             columns=["T_peak", "F_peak", "Width_FWHM", "Area"])
                    pred_idx = model_data["model"].predict(features_df)[0]
                    species_name = model_data["label_encoder"].inverse_transform([pred_idx])[0]

                    return {
                        "filename": file.filename,
                        "sample_id": sample_name,
                        "T_peak": round(T_peak, 4),
                        "F_peak": round(F_peak, 4),
                        "Width_FWHM": round(width, 4),
                        "Area": round(area, 4),
                        "predicted_species": species_name
                    }
                return None

            if 'T' in columns and 'F' in columns:
                res = process_and_predict(
                    pd.to_numeric(df['T'], errors='coerce').values,
                    pd.to_numeric(df['F'], errors='coerce').values,
                    "Uploaded-Sample"
                )
                if res: all_results.append(res)

            for col in columns:
                m = re.match(r"^(.*)T(\d+)$", str(col))
                if m:
                    prefix, num = m.group(1), m.group(2)
                    f_col = f"{prefix}F{num}"
                    if f_col in columns and col not in processed_pairs:
                        processed_pairs.add(col)
                        res = process_and_predict(
                            pd.to_numeric(df[col], errors='coerce').values,
                            pd.to_numeric(df[f_col], errors='coerce').values,
                            f"{prefix}-{num}"
                        )
                        if res: all_results.append(res)

        if not all_results:
             return {"success": False, "message": "No valid data found or file format error."}

        return {"success": True, "results": all_results}

    except Exception as e:
        print(f"Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == '__main__':
    port = int(os.environ.get('PORT', 8000))
    uvicorn.run(app, host='0.0.0.0', port=port)