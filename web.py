# -*- coding: utf-8 -*-
"""web.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jJKSdq8rTp3n7Qx3NYIkaOAjJ8xovQzW
"""

from fastapi import FastAPI, File, UploadFile, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from typing import List
import uvicorn
import pandas as pd
import numpy as np
import joblib
import os
import re
import io
import base64
import glob
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ==========================================
# 1. SETUP & ROBUST LOAD DATA
# ==========================================
MODEL_FILENAME = 'orchid_decision_tree_v1.pkl'
# ‡πÑ‡∏°‡πà‡∏ü‡∏¥‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏ï‡∏≤‡∏¢‡∏ï‡∏±‡∏ß ‡πÅ‡∏ï‡πà‡∏à‡∏∞‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå .xlsx ‡∏´‡∏£‡∏∑‡∏≠ .csv ‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÄ‡∏≠‡∏≤‡πÄ‡∏≠‡∏á
TARGET_REF_FILE = 'PROJECT_DATA.xlsx'

MODEL_PATH = os.path.join(os.path.dirname(__file__), MODEL_FILENAME)

model_data = None
ref_df = None

# 1.1 ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•
try:
    if os.path.exists(MODEL_PATH):
        model_data = joblib.load(MODEL_PATH)
        print(f"‚úÖ Model Loaded")
    else:
        print(f"‚ùå Model Not Found")
except Exception as e:
    print(f"‚ùå Error loading model: {e}")

# 1.2 ‡πÇ‡∏´‡∏•‡∏î Reference Data (‡πÅ‡∏ö‡∏ö‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥)
try:
    # ‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå PROJECT_DATA ‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
    current_dir = os.path.dirname(__file__)
    files = os.listdir(current_dir)
    print(f"üìÇ Files in directory: {files}")

    # ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏≥‡∏ß‡πà‡∏≤ PROJECT_DATA ‡∏´‡∏£‡∏∑‡∏≠‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏• xlsx
    ref_file_path = None
    if TARGET_REF_FILE in files:
        ref_file_path = os.path.join(current_dir, TARGET_REF_FILE)
    else:
        # ‡∏ñ‡πâ‡∏≤‡∏´‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠ ‡∏•‡∏≠‡∏á‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå xlsx ‡∏≠‡∏∞‡πÑ‡∏£‡∏Å‡πá‡πÑ‡∏î‡πâ
        excel_files = [f for f in files if f.endswith('.xlsx') or f.endswith('.xls')]
        if excel_files:
            ref_file_path = os.path.join(current_dir, excel_files[0])
            print(f"‚ö†Ô∏è 'PROJECT_DATA.xlsx' not found. Using '{excel_files[0]}' instead.")

    if ref_file_path:
        print(f"üìñ Loading Reference Data from: {ref_file_path}")
        try:
            if ref_file_path.endswith('.csv'):
                ref_df = pd.read_csv(ref_file_path)
            else:
                ref_df = pd.read_excel(ref_file_path)

            # Cleaning: ‡∏ï‡∏±‡∏î‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡πá‡∏Å
            ref_df.columns = ref_df.columns.str.strip()
            print(f"‚úÖ Loaded {len(ref_df)} rows. Columns example: {list(ref_df.columns[:5])}")
        except Exception as e:
            print(f"‚ùå Failed to read reference file: {e}")
    else:
        print(f"‚ùå NO REFERENCE FILE FOUND! (Please upload PROJECT_DATA.xlsx)")

except Exception as e:
    print(f"‚ùå Error during setup: {e}")

# ==========================================
# 2. HELPER FUNCTIONS
# ==========================================
def extract_peak_features(t, f):
    try:
        mask = ~np.isnan(t) & ~np.isnan(f)
        t, f = np.asarray(t[mask]), np.asarray(f[mask])
        if len(t) < 3: return np.nan, np.nan, np.nan, np.nan
        sort_idx = np.argsort(t)
        t, f = t[sort_idx], f[sort_idx]
        peak_idx = np.argmax(f)
        F_peak = float(f[peak_idx])
        T_peak = float(t[peak_idx])
        if hasattr(np, 'trapezoid'): area = float(np.trapezoid(f, x=t))
        else: area = float(np.trapz(f, t))
        half = F_peak / 2.0
        above_half = np.where(f >= half)[0]
        if len(above_half) >= 2: width = float(t[above_half[-1]] - t[above_half[0]])
        else: width = np.nan
        return T_peak, F_peak, width, area
    except:
        return np.nan, np.nan, np.nan, np.nan

def generate_plot_base64(user_t, user_f, species_name):
    """
    ‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≤‡∏ü‡πÅ‡∏ö‡∏ö‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏™‡πâ‡∏ô (Force Plot)
    """
    try:
        plt.figure(figsize=(9, 6))

        has_ref = False

        # --- 1. ‡∏ß‡∏≤‡∏î‡πÄ‡∏™‡πâ‡∏ô Reference ---
        if ref_df is not None and species_name != "Unknown":
            # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤: PtanalbaT -> ptanalba
            clean_name = species_name.replace('sp', '').strip().lower()
            if clean_name.endswith('t'): clean_name = clean_name[:-1]

            print(f"üîç Plotting Ref for key: '{clean_name}'")

            cols = list(ref_df.columns)

            # ‡∏ß‡∏ô‡∏•‡∏π‡∏õ‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå
            for col in cols:
                col_lower = col.lower()

                # ‡πÄ‡∏ä‡πá‡∏Ñ‡πÅ‡∏Ñ‡πà: ‡∏°‡∏µ‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏¢‡∏û‡∏±‡∏ô‡∏ò‡∏∏‡πå‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÑ‡∏´‡∏°? (‡πÄ‡∏ä‡πà‡∏ô 'ptanalba' in 'PtanalbaT1')
                if clean_name in col_lower:

                    # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå T (‡∏°‡∏µ‡∏ï‡∏±‡∏ß T ‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç)
                    if 't' in col_lower and any(c.isdigit() for c in col):

                        # ‡∏´‡∏≤‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå F ‡∏Ñ‡∏π‡πà‡∏Å‡∏±‡∏ô
                        # ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ: ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô T/t ‡∏ï‡∏±‡∏ß‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡πÄ‡∏õ‡πá‡∏ô F/f
                        is_upper = 'T' in col
                        last_t = col.rfind('T') if is_upper else col.rfind('t')

                        target_f = col[:last_t] + ('F' if is_upper else 'f') + col[last_t+1:]

                        if target_f in cols:
                            # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏°‡∏≤‡∏ß‡∏≤‡∏î
                            r_t = pd.to_numeric(ref_df[col], errors='coerce')
                            r_f = pd.to_numeric(ref_df[target_f], errors='coerce')

                            mask = ~np.isnan(r_t) & ~np.isnan(r_f)
                            r_t, r_f = r_t[mask], r_f[mask]

                            if len(r_t) > 0:
                                sort_idx = np.argsort(r_t)
                                # ‡∏ß‡∏≤‡∏î‡πÄ‡∏™‡πâ‡∏ô‡∏™‡∏µ‡πÅ‡∏î‡∏á (‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏ô‡∏≤‡πÅ‡∏•‡∏∞‡πÄ‡∏Ç‡πâ‡∏°‡∏Ç‡∏∂‡πâ‡∏ô)
                                plt.plot(r_t.iloc[sort_idx], r_f.iloc[sort_idx],
                                         color='#d62728', linestyle='-', linewidth=1.2, alpha=0.5)
                                has_ref = True

        if not has_ref:
            print("‚ö†Ô∏è No matching reference columns found to plot.")

        # --- 2. ‡∏ß‡∏≤‡∏î‡πÄ‡∏™‡πâ‡∏ô User (‡∏™‡∏µ‡∏î‡∏≥‡∏´‡∏ô‡∏≤) ---
        plt.plot(user_t, user_f, label='Your Sample', color='black', linewidth=3.0, zorder=10)

        # --- 3. ‡∏ï‡∏Å‡πÅ‡∏ï‡πà‡∏á ---
        plt.title(f"Comparison: {species_name}", fontsize=14, fontweight='bold')
        plt.xlabel("Temperature (¬∞C)", fontsize=12)
        plt.ylabel("Fluorescence (Diff)", fontsize=12)

        # Legend
        from matplotlib.lines import Line2D
        custom_lines = [Line2D([0], [0], color='black', lw=3, label='Your Sample')]
        if has_ref:
            custom_lines.append(Line2D([0], [0], color='#d62728', lw=1.2, alpha=0.8, label=f'Ref: {clean_name} Group'))

        plt.legend(handles=custom_lines, loc='upper right')
        plt.grid(True, linestyle=':', alpha=0.6)
        plt.tight_layout()

        buf = io.BytesIO()
        plt.savefig(buf, format='png', dpi=120)
        plt.close()
        buf.seek(0)
        img_str = base64.b64encode(buf.read()).decode('utf-8')
        return f"data:image/png;base64,{img_str}"

    except Exception as e:
        print(f"Plot Error: {e}")
        plt.close()
        return None

# ==========================================
# 3. API ENDPOINTS
# ==========================================
@app.get("/")
def home():
    ref_msg = f"Loaded ({len(ref_df)} rows)" if ref_df is not None else "NOT FOUND"
    return {"message": f"Orchid AI: Model Loaded, Ref Data: {ref_msg}"}

@app.post("/predict")
async def predict(files: List[UploadFile] = File(...)):
    if not model_data:
        raise HTTPException(status_code=500, detail="Model file not found.")

    all_results = []

    try:
        for file in files:
            contents = await file.read()
            filename = file.filename.lower()
            try:
                if filename.endswith('.csv'):
                    df = pd.read_csv(io.BytesIO(contents))
                else:
                    df = pd.read_excel(io.BytesIO(contents))
            except:
                continue

            columns = df.columns.tolist()
            processed_pairs = set()

            def process_and_predict(t_arr, f_arr, sample_name):
                T_peak, F_peak, width, area = extract_peak_features(t_arr, f_arr)
                if not np.isnan(T_peak):
                    features_df = pd.DataFrame([[T_peak, F_peak, width, area]],
                                             columns=["T_peak", "F_peak", "Width_FWHM", "Area"])

                    pred_idx = model_data["model"].predict(features_df)[0]
                    species_name = model_data["label_encoder"].inverse_transform([pred_idx])[0]

                    probabilities = model_data["model"].predict_proba(features_df)[0]
                    confidence = round(probabilities[pred_idx] * 100, 2)

                    plot_image = generate_plot_base64(t_arr, f_arr, species_name)

                    return {
                        "filename": file.filename,
                        "sample_id": sample_name,
                        "T_peak": round(T_peak, 4),
                        "F_peak": round(F_peak, 4),
                        "Width_FWHM": round(width, 4),
                        "Area": round(area, 4),
                        "predicted_species": species_name,
                        "confidence_score": f"{confidence}%",
                        "plot_image": plot_image
                    }
                return None

            if 'T' in columns and 'F' in columns:
                res = process_and_predict(
                    pd.to_numeric(df['T'], errors='coerce').values,
                    pd.to_numeric(df['F'], errors='coerce').values,
                    "Uploaded-Sample"
                )
                if res: all_results.append(res)

            for col in columns:
                m = re.match(r"^(.*)T(\d+)$", str(col))
                if m:
                    prefix, num = m.group(1), m.group(2)
                    f_col = f"{prefix}F{num}"
                    if f_col in columns and col not in processed_pairs:
                        processed_pairs.add(col)
                        res = process_and_predict(
                            pd.to_numeric(df[col], errors='coerce').values,
                            pd.to_numeric(df[f_col], errors='coerce').values,
                            f"{prefix}-{num}"
                        )
                        if res: all_results.append(res)

        if not all_results:
             return {"success": False, "message": "No valid data found."}

        return {"success": True, "results": all_results}

    except Exception as e:
        raise HTTPException(status_code=550, detail=str(e))

if __name__ == '__main__':
    port = int(os.environ.get('PORT', 8000))
    uvicorn.run(app, host='0.0.0.0', port=port)