# -*- coding: utf-8 -*-
"""web.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BL6rGfcjRjgT-hPDLiIJHgnvx2CM4R33
"""

from fastapi import FastAPI, UploadFile, File
from fastapi.middleware.cors import CORSMiddleware
import pandas as pd
import numpy as np
import joblib
import io

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# โหลดโมเดล
artifacts = joblib.load("orchid_decision_tree_v1.pkl")
model = artifacts["model"]
le = artifacts["label_encoder"]
medians = artifacts["medians"]
feat_cols = artifacts["feature_columns"]

def extract_peak_features(t, f):
    mask = ~np.isnan(t) & ~np.isnan(f)
    t = np.asarray(t[mask])
    f = np.asarray(f[mask])

    if len(t) < 3: return np.nan, np.nan, np.nan, np.nan

    sort_idx = np.argsort(t)
    t = t[sort_idx]
    f = f[sort_idx]

    peak_idx = np.argmax(f)
    F_peak = float(f[peak_idx])
    T_peak = float(t[peak_idx])
    area = float(np.trapz(f, t))

    half = F_peak / 2.0
    above_half = np.where(f >= half)[0]
    if len(above_half) >= 2:
        width = float(t[above_half[-1]] - t[above_half[0]])
    else:
        width = np.nan

    return T_peak, F_peak, width, area

def process_file(df):
    columns = df.columns.tolist()
    features = []

    # จับคู่ตามตำแหน่ง (ไม่สนชื่อหัวตาราง)
    for i in range(0, len(columns) - 1, 2):
        t_col = columns[i]
        f_col = columns[i+1]

        t_vals = pd.to_numeric(df[t_col], errors='coerce').values
        f_vals = pd.to_numeric(df[f_col], errors='coerce').values

        T_peak, F_peak, width, area = extract_peak_features(t_vals, f_vals)

        features.append({
            "T_peak": T_peak,
            "F_peak": F_peak,
            "Width_FWHM": width,
            "Area": area
        })

    feat_df = pd.DataFrame(features)

    if not feat_df.empty:
        for col in feat_cols:
            if col not in feat_df.columns: feat_df[col] = np.nan
            feat_df[col] = feat_df[col].astype(float)
            if col in medians: feat_df[col] = feat_df[col].fillna(medians[col])

    return feat_df

@app.post("/predict")
async def predict(file: UploadFile = File(...)):
    try:
        contents = await file.read()
        df = pd.read_excel(io.BytesIO(contents))

        processed_df = process_file(df)

        if processed_df.empty:
            return {"error": "ไม่พบข้อมูลที่จับคู่กันได้ในไฟล์"}

        X = processed_df[feat_cols].to_numpy()

        # คำนวณความน่าจะเป็น
        probabilities = model.predict_proba(X)
        class_labels = model.classes_

        results = []
        for i in range(len(processed_df)):
            probs = probabilities[i]

            # เรียงลำดับสายพันธุ์ภายในแถว (Top 4)
            top_indices = np.argsort(probs)[::-1]
            top_4_indices = top_indices[:4]

            # สร้างข้อความแสดงผล
            top_4_list = []
            max_score = 0.0 # เก็บค่าความมั่นใจสูงสุดไว้ใช้เรียงบรรทัด

            for k, idx in enumerate(top_4_indices):
                species = class_labels[idx]
                score = probs[idx] * 100

                # เก็บค่าสูงสุดของแถวนี้
                if k == 0:
                    max_score = score

                if score > 0.0:
                    top_4_list.append(f"{species} ({score:.2f}%)")

            display_text = ", ".join(top_4_list)

            results.append({
                "top_4_result": display_text,
                "sort_score": max_score # ใส่ไว้สำหรับเรียงลำดับ
            })

        # --- จุดสำคัญ: เรียงลำดับแถวตามความมั่นใจ (มาก -> น้อย) ---
        results.sort(key=lambda x: x["sort_score"], reverse=True)

        return {"results": results}

    except Exception as e:
        return {"error": str(e)}