# -*- coding: utf-8 -*-
"""web.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jJKSdq8rTp3n7Qx3NYIkaOAjJ8xovQzW
"""

from fastapi import FastAPI, File, UploadFile, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from typing import List
import uvicorn
import pandas as pd
import numpy as np
import joblib
import os
import re
import io
import base64
import matplotlib
matplotlib.use('Agg') # Backend สำหรับ Server (ไม่โชว์หน้าต่าง)
import matplotlib.pyplot as plt

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ==========================================
# 1. SETUP & LOAD DATA
# ==========================================
MODEL_FILENAME = 'orchid_decision_tree_v1.pkl'
REF_DATA_FILENAME = 'PROJECT_DATA.xlsx'

MODEL_PATH = os.path.join(os.path.dirname(__file__), MODEL_FILENAME)
REF_PATH = os.path.join(os.path.dirname(__file__), REF_DATA_FILENAME)

model_data = None
ref_df = None

# 1.1 โหลดโมเดล
try:
    if os.path.exists(MODEL_PATH):
        model_data = joblib.load(MODEL_PATH)
        print(f"✅ Model Loaded Successfully")
    else:
        print(f"❌ Model Not Found at {MODEL_PATH}")
except Exception as e:
    print(f"❌ Error loading model: {e}")

# 1.2 โหลด Reference Data (PROJECT_DATA)
try:
    if os.path.exists(REF_PATH):
        try:
            if REF_DATA_FILENAME.endswith('.csv'):
                ref_df = pd.read_csv(REF_PATH)
            else:
                ref_df = pd.read_excel(REF_PATH)
        except:
            ref_df = pd.read_excel(REF_PATH)

        # Cleaning: ตัดช่องว่างและทำเป็นตัวพิมพ์เล็กทั้งหมดเพื่อการค้นหาที่แม่นยำ
        ref_df.columns = ref_df.columns.str.strip()
        print(f"✅ Reference Data Loaded: {len(ref_df)} rows")
    else:
        print(f"⚠️ Reference Data Not Found! (Plot will have no background lines)")
except Exception as e:
    print(f"⚠️ Error loading reference data: {e}")

# ==========================================
# 2. HELPER FUNCTIONS
# ==========================================
def extract_peak_features(t, f):
    try:
        mask = ~np.isnan(t) & ~np.isnan(f)
        t, f = np.asarray(t[mask]), np.asarray(f[mask])
        if len(t) < 3: return np.nan, np.nan, np.nan, np.nan

        sort_idx = np.argsort(t)
        t, f = t[sort_idx], f[sort_idx]

        peak_idx = np.argmax(f)
        F_peak = float(f[peak_idx])
        T_peak = float(t[peak_idx])

        if hasattr(np, 'trapezoid'): area = float(np.trapezoid(f, x=t))
        else: area = float(np.trapz(f, t))

        half = F_peak / 2.0
        above_half = np.where(f >= half)[0]
        if len(above_half) >= 2:
            width = float(t[above_half[-1]] - t[above_half[0]])
        else: width = np.nan

        return T_peak, F_peak, width, area
    except:
        return np.nan, np.nan, np.nan, np.nan

def generate_plot_base64(user_t, user_f, species_name):
    """
    สร้างกราฟเปรียบเทียบ:
    1. วาดเส้น Reference ทั้งหมด (สีแดงจางๆ) เป็น Background
    2. วาดเส้น User (สีดำหนา) ทับด้านหน้า
    """
    try:
        plt.figure(figsize=(8, 5))

        has_ref_lines = False

        # --- ส่วนที่ 1: วาดเส้น Reference (Project Data) ---
        if ref_df is not None and species_name != "Unknown":
            # เตรียมคำค้นหา: "PtanalbaT" -> "ptanalba"
            # 1. ตัด sp
            clean_name = species_name.replace('sp', '').strip()
            # 2. ถ้าลงท้ายด้วย T หรือ t ให้ตัดทิ้ง
            if clean_name.endswith('T') or clean_name.endswith('t'):
                 clean_name = clean_name[:-1]

            search_key = clean_name.lower() # ใช้ตัวพิมพ์เล็กค้นหา

            # กวาดทุกคอลัมน์ใน Excel
            cols = list(ref_df.columns)

            for col in cols:
                col_lower = col.lower()

                # Logic: ชื่อคอลัมน์ต้องมีคำค้นหา และต้องเป็นคอลัมน์ T (มี T ตามด้วยตัวเลข)
                if search_key in col_lower and 't' in col_lower and any(c.isdigit() for c in col):

                    # หาคอลัมน์ F คู่กัน
                    # หาตำแหน่ง T สุดท้าย (ไม่ว่าจะ T ใหญ่หรือ t เล็ก)
                    is_upper = 'T' in col
                    last_t_idx = col.rfind('T') if is_upper else col.rfind('t')

                    # สร้างชื่อ F ที่ควรจะเป็น
                    col_f = col[:last_t_idx] + ('F' if is_upper else 'f') + col[last_t_idx+1:]

                    # ถ้ามีคอลัมน์ F นี้อยู่จริง -> วาดเส้นเลย
                    if col_f in cols:
                        ref_t = pd.to_numeric(ref_df[col], errors='coerce')
                        ref_f = pd.to_numeric(ref_df[col_f], errors='coerce')

                        mask = ~np.isnan(ref_t) & ~np.isnan(ref_f)
                        ref_t, ref_f = ref_t[mask], ref_f[mask]

                        if len(ref_t) > 0:
                            sort_idx = np.argsort(ref_t)
                            # วาดเส้นสีแดงจางๆ (alpha=0.3)
                            plt.plot(ref_t.iloc[sort_idx], ref_f.iloc[sort_idx],
                                     color='#ff3333', linestyle='-', linewidth=0.8, alpha=0.3)
                            has_ref_lines = True

        # --- ส่วนที่ 2: วาดเส้น User (สีดำหนา) ---
        plt.plot(user_t, user_f, label='Your Sample', color='black', linewidth=2.5)

        # --- ตกแต่งกราฟ ---
        plt.title(f"Comparison: {species_name}", fontsize=14, fontweight='bold')
        plt.xlabel("Temperature (°C)", fontsize=12)
        plt.ylabel("Fluorescence (Diff)", fontsize=12)

        # Legend (สร้างหลอกๆ ให้ดูสะอาดตา)
        from matplotlib.lines import Line2D
        legend_elements = [
            Line2D([0], [0], color='black', lw=2.5, label='Your Sample'),
        ]
        if has_ref_lines:
             legend_elements.append(Line2D([0], [0], color='#ff3333', lw=1, alpha=0.6, label='Reference Group'))

        plt.legend(handles=legend_elements, loc='upper right')
        plt.grid(True, linestyle=':', alpha=0.6)
        plt.tight_layout()

        # Save to Base64
        buf = io.BytesIO()
        plt.savefig(buf, format='png', dpi=120)
        plt.close()
        buf.seek(0)
        img_str = base64.b64encode(buf.read()).decode('utf-8')
        return f"data:image/png;base64,{img_str}"

    except Exception as e:
        print(f"Plot Error: {e}")
        plt.close()
        return None

# ==========================================
# 3. API ENDPOINTS
# ==========================================
@app.get("/")
def home():
    ref_status = "Loaded" if ref_df is not None else "Not Found"
    return {"message": f"Orchid AI Ready. Ref Data: {ref_status}"}

@app.post("/predict")
async def predict(files: List[UploadFile] = File(...)):
    if not model_data:
        raise HTTPException(status_code=500, detail="Model file not found.")

    all_results = []

    try:
        for file in files:
            contents = await file.read()
            filename = file.filename.lower()
            try:
                if filename.endswith('.csv'):
                    df = pd.read_csv(io.BytesIO(contents))
                else:
                    df = pd.read_excel(io.BytesIO(contents))
            except:
                continue

            columns = df.columns.tolist()
            processed_pairs = set()

            def process_and_predict(t_arr, f_arr, sample_name):
                T_peak, F_peak, width, area = extract_peak_features(t_arr, f_arr)
                if not np.isnan(T_peak):
                    features_df = pd.DataFrame([[T_peak, F_peak, width, area]],
                                             columns=["T_peak", "F_peak", "Width_FWHM", "Area"])

                    # Prediction
                    pred_idx = model_data["model"].predict(features_df)[0]
                    species_name = model_data["label_encoder"].inverse_transform([pred_idx])[0]

                    # Confidence
                    probabilities = model_data["model"].predict_proba(features_df)[0]
                    confidence = round(probabilities[pred_idx] * 100, 2)

                    # Plotting
                    plot_image = generate_plot_base64(t_arr, f_arr, species_name)

                    return {
                        "filename": file.filename,
                        "sample_id": sample_name,
                        "T_peak": round(T_peak, 4),
                        "F_peak": round(F_peak, 4),
                        "Width_FWHM": round(width, 4),
                        "Area": round(area, 4),
                        "predicted_species": species_name,
                        "confidence_score": f"{confidence}%",
                        "plot_image": plot_image
                    }
                return None

            # Case: T, F columns (User uploaded file)
            if 'T' in columns and 'F' in columns:
                res = process_and_predict(
                    pd.to_numeric(df['T'], errors='coerce').values,
                    pd.to_numeric(df['F'], errors='coerce').values,
                    "Uploaded-Sample"
                )
                if res: all_results.append(res)

            # Case: Multiple columns
            for col in columns:
                m = re.match(r"^(.*)T(\d+)$", str(col))
                if m:
                    prefix, num = m.group(1), m.group(2)
                    f_col = f"{prefix}F{num}"
                    if f_col in columns and col not in processed_pairs:
                        processed_pairs.add(col)
                        res = process_and_predict(
                            pd.to_numeric(df[col], errors='coerce').values,
                            pd.to_numeric(df[f_col], errors='coerce').values,
                            f"{prefix}-{num}"
                        )
                        if res: all_results.append(res)

        if not all_results:
             return {"success": False, "message": "No valid data found."}

        return {"success": True, "results": all_results}

    except Exception as e:
        raise HTTPException(status_code=550, detail=str(e))

if __name__ == '__main__':
    port = int(os.environ.get('PORT', 8000))
    uvicorn.run(app, host='0.0.0.0', port=port)