# -*- coding: utf-8 -*-
"""web.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12w-zLfUrcKXiEDE-uvGpt7VtLst2_9e_
"""

from fastapi import FastAPI, UploadFile, File
from fastapi.middleware.cors import CORSMiddleware
import pandas as pd
import numpy as np
import joblib
import io
import traceback
import re
from collections import defaultdict

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/")
def home():
    return {"message": "Orchid API is running!"}

# --- 1. โหลดโมเดล (Decision Tree) ---
try:
    artifacts = joblib.load("orchid_decision_tree_v1.pkl")
    model = artifacts["model"]
    le = artifacts["label_encoder"]
    feat_cols = artifacts["feature_columns"]
    class_labels = model.classes_
    print("✅ Model loaded successfully.")
except Exception as e:
    print(f"❌ Model loading failed: {e}")
    model = None
    le = None

# --- 2. ฟังก์ชันสกัด Feature (เหมือนของเพื่อนคุณ) ---
def extract_peak_features(t, f):
    mask = ~np.isnan(t) & ~np.isnan(f)
    t = np.asarray(t[mask])
    f = np.asarray(f[mask])
    if len(t) < 3: return np.nan, np.nan, np.nan, np.nan

    sort_idx = np.argsort(t)
    t = t[sort_idx]
    f = f[sort_idx]

    peak_idx = np.argmax(f)
    F_peak = float(f[peak_idx])
    T_peak = float(t[peak_idx])

    # รองรับ numpy เวอร์ชันใหม่ (trapezoid) และเก่า (trapz)
    if hasattr(np, 'trapezoid'):
        area = float(np.trapezoid(f, x=t))
    else:
        area = float(np.trapz(f, t))

    half = F_peak / 2.0
    above_half = np.where(f >= half)[0]
    if len(above_half) >= 2:
        width = float(t[above_half[-1]] - t[above_half[0]])
    else:
        width = np.nan
    return T_peak, F_peak, width, area

# --- 3. ฟังก์ชันดึงชื่อกลุ่ม (ใช้ตรรกะเดียวกับ finish_model.py) ---
def get_species_group_name(col_name):
    # ใช้ Regex ดึงเฉพาะตัวอักษรภาษาอังกฤษข้างหน้า
    # เช่น "PtanalbaT1" -> "Ptanalba", "Csp015T3" -> "Csp"
    m = re.match(r"^([A-Za-z]+)", str(col_name))
    if m:
        return m.group(1)
    return "Unknown"

# --- 4. ฟังก์ชันหลัก: จัดกลุ่มและเตรียมข้อมูล ---
def process_file_and_group(df):
    columns = df.columns.tolist()
    grouped_data = defaultdict(list)

    # วนลูปจับคู่ T และ F
    for i in range(0, len(columns) - 1, 2):
        t_col = columns[i]
        f_col = columns[i+1]

        # ดึงชื่อกลุ่ม (เช่น Ptanalba)
        group_name = get_species_group_name(t_col)

        t_vals = pd.to_numeric(df[t_col], errors='coerce').values
        f_vals = pd.to_numeric(df[f_col], errors='coerce').values

        T_peak, F_peak, width, area = extract_peak_features(t_vals, f_vals)

        if not np.isnan(T_peak):
            # เก็บค่าฟีเจอร์ลงในกลุ่มนั้นๆ
            grouped_data[group_name].append([T_peak, F_peak, width, area])

    return grouped_data

@app.post("/predict")
async def predict(file: UploadFile = File(...)):
    try:
        if model is None: return {"results": []}

        contents = await file.read()
        df = pd.read_excel(io.BytesIO(contents))

        # 1. จัดกลุ่มข้อมูล (Group Similar Names)
        grouped_features = process_file_and_group(df)

        if not grouped_features: return {"results": []}

        results = []

        # 2. วิเคราะห์ทีละกลุ่ม (Combine & Analyze)
        for group_name, features_list in grouped_features.items():
            # แปลงข้อมูลทั้งหมดในกลุ่มเป็น Array เดียว
            X_group = np.array(features_list)

            # ให้ Model ทำนายความน่าจะเป็นของทุกเส้นในกลุ่มนี้
            probs_group = model.predict_proba(X_group)

            # *** รวมผลลัพธ์: หาค่าเฉลี่ยความน่าจะเป็นของทั้งกลุ่ม ***
            # นี่คือขั้นตอนที่ยุบหลาย Sample ให้เหลือผลลัพธ์เดียว
            avg_probs = np.mean(probs_group, axis=0)

            # หา Top 4 จากค่าเฉลี่ย
            top_indices = np.argsort(avg_probs)[::-1][:4]

            top_4_data = []
            max_score = 0.0

            # สร้างข้อความผลลัพธ์ (List 1-4)
            for k, idx in enumerate(top_indices):
                pred_label_code = class_labels[idx]
                try:
                    species_name = le.inverse_transform([pred_label_code])[0]
                except:
                    species_name = "Unknown"

                score = int(round(avg_probs[idx] * 100))
                if k == 0: max_score = score

                if score >= 0:
                    display_text = f"{k + 1}. {species_name} {score}%"
                    top_4_data.append({
                        "rank": k + 1,
                        "species": display_text,
                        "confidence": score
                    })

            results.append({
                # ส่งค่าว่างไปที่ filename เพื่อซ่อนชื่อกลุ่มในหน้าเว็บ (Trick)
                "filename": "",
                "group_real_name": group_name,
                "top_4_details": top_4_data,
                "sort_score": max_score
            })

        # เรียงลำดับบรรทัดตามคะแนนความมั่นใจ
        results.sort(key=lambda x: x["sort_score"], reverse=True)
        return {"results": results}

    except Exception as e:
        print(traceback.format_exc())
        return {"results": []}