# -*- coding: utf-8 -*-
"""web.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jJKSdq8rTp3n7Qx3NYIkaOAjJ8xovQzW
"""

from fastapi import FastAPI, File, UploadFile, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from typing import List
import uvicorn
import pandas as pd
import numpy as np
import joblib
import os
import re
import io
import base64
import glob  # ‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
import matplotlib
matplotlib.use('Agg') # ‡πÉ‡∏ä‡πâ Backend ‡πÅ‡∏ö‡∏ö‡πÑ‡∏°‡πà‡πÅ‡∏™‡∏î‡∏á‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á
import matplotlib.pyplot as plt

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ==========================================
# 1. SETUP & ROBUST FILE LOADING
# ==========================================
MODEL_FILENAME = 'orchid_decision_tree_v1.pkl'
MODEL_PATH = os.path.join(os.path.dirname(__file__), MODEL_FILENAME)

model_data = None
ref_df = None

# 1.1 Load Model
try:
    if os.path.exists(MODEL_PATH):
        model_data = joblib.load(MODEL_PATH)
        print(f"‚úÖ Model Loaded")
    else:
        print(f"‚ùå Model Not Found at {MODEL_PATH}")
except Exception as e:
    print(f"‚ùå Error loading model: {e}")

# 1.2 Load Reference Data (PROJECT_DATA.xlsx)
# ‡πÉ‡∏ä‡πâ glob ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå .xlsx ‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏™‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏ß‡πà‡∏≤‡∏û‡∏¥‡∏°‡∏û‡πå‡πÄ‡∏•‡πá‡∏Å/‡πÉ‡∏´‡∏ç‡πà
try:
    current_dir = os.path.dirname(__file__)
    # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå Excel ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
    excel_files = glob.glob(os.path.join(current_dir, "*.xlsx"))
    csv_files = glob.glob(os.path.join(current_dir, "*.csv"))

    # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå PROJECT_DATA ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ ‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏≠‡∏≤‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏£‡∏Å‡∏ó‡∏µ‡πà‡πÄ‡∏à‡∏≠
    found_file = None
    target_name = "PROJECT_DATA.xlsx"

    # ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏ä‡∏∑‡πà‡∏≠‡∏ï‡∏£‡∏á‡πÄ‡∏õ‡πä‡∏∞‡∏Å‡πà‡∏≠‡∏ô
    if os.path.exists(os.path.join(current_dir, target_name)):
        found_file = os.path.join(current_dir, target_name)
    elif excel_files:
        found_file = excel_files[0] # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡πä‡∏∞ ‡πÄ‡∏≠‡∏≤‡πÑ‡∏ü‡∏•‡πå Excel ‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏£‡∏Å‡∏ó‡∏µ‡πà‡πÄ‡∏à‡∏≠
    elif csv_files:
        found_file = csv_files[0]

    if found_file:
        print(f"üìñ Reference File Found: {found_file}")
        if found_file.endswith('.csv'):
            ref_df = pd.read_csv(found_file)
        else:
            ref_df = pd.read_excel(found_file)

        # Cleaning: ‡∏ï‡∏±‡∏î‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á‡∏´‡∏±‡∏ß‡∏ó‡πâ‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå
        ref_df.columns = ref_df.columns.str.strip()
        print(f"‚úÖ Reference Data Loaded: {len(ref_df)} rows")
    else:
        print(f"‚ùå CRITICAL: No Reference File Found in {current_dir}")
        print("   Please upload PROJECT_DATA.xlsx to GitHub.")

except Exception as e:
    print(f"‚ùå Error loading reference data: {e}")

# ==========================================
# 2. HELPER FUNCTIONS
# ==========================================
def extract_peak_features(t, f):
    try:
        mask = ~np.isnan(t) & ~np.isnan(f)
        t, f = np.asarray(t[mask]), np.asarray(f[mask])
        if len(t) < 3: return np.nan, np.nan, np.nan, np.nan
        sort_idx = np.argsort(t)
        t, f = t[sort_idx], f[sort_idx]
        peak_idx = np.argmax(f)
        F_peak = float(f[peak_idx])
        T_peak = float(t[peak_idx])
        if hasattr(np, 'trapezoid'): area = float(np.trapezoid(f, x=t))
        else: area = float(np.trapz(f, t))
        half = F_peak / 2.0
        above_half = np.where(f >= half)[0]
        if len(above_half) >= 2: width = float(t[above_half[-1]] - t[above_half[0]])
        else: width = np.nan
        return T_peak, F_peak, width, area
    except:
        return np.nan, np.nan, np.nan, np.nan

def generate_plot_base64(user_t, user_f, species_name):
    """
    ‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≤‡∏ü‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö:
    1. ‡∏ß‡∏≤‡∏î‡πÄ‡∏™‡πâ‡∏ô Reference ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á (‡∏™‡∏µ‡πÅ‡∏î‡∏á‡∏à‡∏≤‡∏á‡πÜ)
    2. ‡∏ß‡∏≤‡∏î‡πÄ‡∏™‡πâ‡∏ô User Data (‡∏™‡∏µ‡∏î‡∏≥‡∏´‡∏ô‡∏≤) ‡∏ó‡∏±‡∏ö‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô
    """
    try:
        plt.figure(figsize=(10, 6))

        has_ref = False

        # --- 1. ‡∏ß‡∏≤‡∏î‡πÄ‡∏™‡πâ‡∏ô Reference (Background) ---
        if ref_df is not None:
            # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤: ‡∏ï‡∏±‡∏î sp, ‡∏ï‡∏±‡∏î T ‡∏ó‡πâ‡∏≤‡∏¢‡∏Ñ‡∏≥
            # ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: "PtanalbaT" -> "Ptanalba"
            target_species = species_name.strip()
            if target_species.endswith('T') or target_species.endswith('t'):
                target_species = target_species[:-1]
            if target_species.lower().endswith('sp'):
                target_species = target_species.lower().replace('sp', '').strip()

            print(f"Plotting references for: {target_species}")

            # ‡πÉ‡∏ä‡πâ Regex ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ó‡∏µ‡πà‡∏Ç‡∏∂‡πâ‡∏ô‡∏ï‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏¢‡∏û‡∏±‡∏ô‡∏ò‡∏∏‡πå ‡πÅ‡∏•‡∏∞‡∏ï‡∏≤‡∏°‡∏î‡πâ‡∏ß‡∏¢ T + ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç
            # ‡πÄ‡∏ä‡πà‡∏ô PtanalbaT1, PtanalbaT2, ...
            pattern = re.compile(f"^{re.escape(target_species)}T\\d+$", re.IGNORECASE)

            cols = ref_df.columns
            ref_pairs = []

            # ‡∏ß‡∏ô‡∏•‡∏π‡∏õ‡∏´‡∏≤‡∏Ñ‡∏π‡πà T, F ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
            for col in cols:
                if pattern.match(col):
                    # ‡πÄ‡∏à‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå T -> ‡∏´‡∏≤‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå F ‡∏Ñ‡∏π‡πà‡∏Å‡∏±‡∏ô
                    is_upper = 'T' in col
                    last_t_idx = col.rfind('T') if is_upper else col.rfind('t')
                    col_f = col[:last_t_idx] + ('F' if is_upper else 'f') + col[last_t_idx+1:]

                    if col_f in cols:
                        ref_pairs.append((col, col_f))

            # ‡∏ß‡∏≤‡∏î‡πÄ‡∏™‡πâ‡∏ô‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏π‡πà‡∏ó‡∏µ‡πà‡πÄ‡∏à‡∏≠
            for t_col, f_col in ref_pairs:
                r_t = pd.to_numeric(ref_df[t_col], errors='coerce')
                r_f = pd.to_numeric(ref_df[f_col], errors='coerce')

                mask = ~np.isnan(r_t) & ~np.isnan(r_f)
                r_t, r_f = r_t[mask], r_f[mask]

                if len(r_t) > 0:
                    sort_idx = np.argsort(r_t)
                    # ‡πÄ‡∏™‡πâ‡∏ô‡∏™‡∏µ‡πÅ‡∏î‡∏á‡∏à‡∏≤‡∏á‡πÜ (Reference Group)
                    plt.plot(r_t.iloc[sort_idx], r_f.iloc[sort_idx],
                             color='#ff3333', linestyle='--', linewidth=1, alpha=0.4)
                    has_ref = True

        # --- 2. ‡∏ß‡∏≤‡∏î‡πÄ‡∏™‡πâ‡∏ô User Data (Foreground) ---
        # ‡πÄ‡∏™‡πâ‡∏ô‡∏™‡∏µ‡∏î‡∏≥‡∏´‡∏ô‡∏≤ (Your Sample)
        plt.plot(user_t, user_f, label='Your Sample', color='black', linewidth=3.0, zorder=10)

        # --- 3. ‡∏ï‡∏Å‡πÅ‡∏ï‡πà‡∏á‡∏Å‡∏£‡∏≤‡∏ü ---
        plt.title(f"Comparison: User Sample vs {species_name} Group", fontsize=14, fontweight='bold')
        plt.xlabel("Temperature (¬∞C)", fontsize=12)
        plt.ylabel("Fluorescence (Diff)", fontsize=12)
        plt.grid(True, linestyle=':', alpha=0.6)

        # Legend
        from matplotlib.lines import Line2D
        legend_elements = [
            Line2D([0], [0], color='black', lw=3, label='Your Sample'),
        ]
        if has_ref:
            legend_elements.append(Line2D([0], [0], color='#ff3333', lw=1, linestyle='--', label=f'Ref: {species_name} Group'))

        plt.legend(handles=legend_elements, loc='upper right')
        plt.tight_layout()

        # Save to Base64
        buf = io.BytesIO()
        plt.savefig(buf, format='png', dpi=120)
        plt.close()
        buf.seek(0)
        img_str = base64.b64encode(buf.read()).decode('utf-8')
        return f"data:image/png;base64,{img_str}"

    except Exception as e:
        print(f"Plot Error: {e}")
        plt.close()
        return None

# ==========================================
# 3. API ENDPOINTS
# ==========================================
@app.get("/")
def home():
    ref_status = f"Loaded ({len(ref_df)} rows)" if ref_df is not None else "NOT FOUND"
    return {"message": f"Orchid AI Ready. Ref File: {ref_status}"}

@app.post("/predict")
async def predict(files: List[UploadFile] = File(...)):
    if not model_data:
        raise HTTPException(status_code=500, detail="Model file not found.")

    all_results = []

    try:
        for file in files:
            contents = await file.read()
            filename = file.filename.lower()
            try:
                if filename.endswith('.csv'):
                    df = pd.read_csv(io.BytesIO(contents))
                else:
                    df = pd.read_excel(io.BytesIO(contents))
            except:
                continue

            columns = df.columns.tolist()
            processed_pairs = set()

            def process_and_predict(t_arr, f_arr, sample_name):
                T_peak, F_peak, width, area = extract_peak_features(t_arr, f_arr)
                if not np.isnan(T_peak):
                    features_df = pd.DataFrame([[T_peak, F_peak, width, area]],
                                             columns=["T_peak", "F_peak", "Width_FWHM", "Area"])

                    # Predict
                    pred_idx = model_data["model"].predict(features_df)[0]
                    species_name = model_data["label_encoder"].inverse_transform([pred_idx])[0]

                    # Confidence
                    probabilities = model_data["model"].predict_proba(features_df)[0]
                    confidence = round(probabilities[pred_idx] * 100, 2)

                    # Plot
                    plot_image = generate_plot_base64(t_arr, f_arr, species_name)

                    return {
                        "filename": file.filename,
                        "sample_id": sample_name,
                        "T_peak": round(T_peak, 4),
                        "F_peak": round(F_peak, 4),
                        "Width_FWHM": round(width, 4),
                        "Area": round(area, 4),
                        "predicted_species": species_name,
                        "confidence_score": f"{confidence}%",
                        "plot_image": plot_image
                    }
                return None

            # User file usually has 'T' and 'F' columns
            if 'T' in columns and 'F' in columns:
                res = process_and_predict(
                    pd.to_numeric(df['T'], errors='coerce').values,
                    pd.to_numeric(df['F'], errors='coerce').values,
                    "Uploaded-Sample"
                )
                if res: all_results.append(res)

            # Support multi-column format just in case
            for col in columns:
                m = re.match(r"^(.*)T(\d+)$", str(col))
                if m:
                    prefix, num = m.group(1), m.group(2)
                    f_col = f"{prefix}F{num}"
                    if f_col in columns and col not in processed_pairs:
                        processed_pairs.add(col)
                        res = process_and_predict(
                            pd.to_numeric(df[col], errors='coerce').values,
                            pd.to_numeric(df[f_col], errors='coerce').values,
                            f"{prefix}-{num}"
                        )
                        if res: all_results.append(res)

        if not all_results:
             return {"success": False, "message": "No valid data found."}

        return {"success": True, "results": all_results}

    except Exception as e:
        raise HTTPException(status_code=550, detail=str(e))

if __name__ == '__main__':
    port = int(os.environ.get('PORT', 8000))
    uvicorn.run(app, host='0.0.0.0', port=port)