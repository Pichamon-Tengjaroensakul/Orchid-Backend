# -*- coding: utf-8 -*-
"""web.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jJKSdq8rTp3n7Qx3NYIkaOAjJ8xovQzW
"""

from fastapi import FastAPI, File, UploadFile, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from typing import List
import uvicorn
import pandas as pd
import numpy as np
import joblib
import os
import re
import io
import base64
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ==========================================
# 1. SETUP MODEL & REFERENCE DATA
# ==========================================
MODEL_FILENAME = 'orchid_decision_tree_v1.pkl'
REF_DATA_FILENAME = 'PROJECT_DATA.xlsx' # ✅ ต้องมีไฟล์นี้ใน GitHub คู่กับ web.py

MODEL_PATH = os.path.join(os.path.dirname(__file__), MODEL_FILENAME)
REF_PATH = os.path.join(os.path.dirname(__file__), REF_DATA_FILENAME)

model_data = None
ref_df = None

# Load Model
try:
    if os.path.exists(MODEL_PATH):
        model_data = joblib.load(MODEL_PATH)
        print(f"✅ Model Loaded: {MODEL_FILENAME}")
    else:
        print(f"❌ Model Not Found: {MODEL_PATH}")
except Exception as e:
    print(f"❌ Error loading model: {e}")

# Load Reference Data
try:
    if os.path.exists(REF_PATH):
        # เช็คว่าเป็น CSV หรือ Excel
        if REF_DATA_FILENAME.endswith('.csv'):
            ref_df = pd.read_csv(REF_PATH)
        else:
            ref_df = pd.read_excel(REF_PATH)
        print(f"✅ Reference Data Loaded: {REF_DATA_FILENAME} ({len(ref_df)} rows)")
    else:
        print(f"⚠️ Reference Data Not Found at: {REF_PATH}")
except Exception as e:
    print(f"⚠️ Error loading reference data: {e}")

# ==========================================
# 2. FUNCTIONS
# ==========================================
def extract_peak_features(t, f):
    try:
        mask = ~np.isnan(t) & ~np.isnan(f)
        t, f = np.asarray(t[mask]), np.asarray(f[mask])
        if len(t) < 3: return np.nan, np.nan, np.nan, np.nan

        sort_idx = np.argsort(t)
        t, f = t[sort_idx], f[sort_idx]

        peak_idx = np.argmax(f)
        F_peak = float(f[peak_idx])
        T_peak = float(t[peak_idx])

        if hasattr(np, 'trapezoid'): area = float(np.trapezoid(f, x=t))
        else: area = float(np.trapz(f, t))

        half = F_peak / 2.0
        above_half = np.where(f >= half)[0]
        if len(above_half) >= 2:
            width = float(t[above_half[-1]] - t[above_half[0]])
        else: width = np.nan

        return T_peak, F_peak, width, area
    except:
        return np.nan, np.nan, np.nan, np.nan

def generate_plot_base64(user_t, user_f, species_name):
    try:
        plt.figure(figsize=(7, 4.5)) # ปรับขนาดให้สวยงาม

        # 1. วาดเส้น User (Blue)
        plt.plot(user_t, user_f, label='Your Sample', color='blue', linewidth=2.5)

        # 2. วาดเส้น Reference (Red) ถ้ามีข้อมูล
        if ref_df is not None and species_name != "Unknown":
            cols = ref_df.columns
            found = False

            # Logic หาคอลัมน์: พยายามหาคอลัมน์ที่มีชื่อสายพันธุ์
            # ตัวอย่างชื่อคอลัมน์: "PtanalbaT1", "PtanalbaF1"
            search_name = species_name.split(' ')[0] # เอาคำแรก (เช่น Ptanalba)

            for col in cols:
                # ถ้าเจอหัวคอลัมน์ที่มีชื่อสายพันธุ์ และลงท้ายด้วย T และตัวเลข
                if search_name in str(col) and 'T' in str(col):
                    # หาคู่ F ของมัน
                    # สมมติ col = PtanalbaT1 -> หา PtanalbaF1
                    prefix = str(col).split('T')[0] # Ptanalba
                    suffix = str(col).split('T')[-1] # 1
                    f_col = f"{prefix}F{suffix}"

                    if f_col in cols:
                        ref_t_raw = pd.to_numeric(ref_df[col], errors='coerce')
                        ref_f_raw = pd.to_numeric(ref_df[f_col], errors='coerce')

                        # ลบค่า Nan และ Sort
                        mask = ~np.isnan(ref_t_raw) & ~np.isnan(ref_f_raw)
                        ref_t = ref_t_raw[mask]
                        ref_f = ref_f_raw[mask]

                        sort_idx = np.argsort(ref_t)

                        # วาดเส้นแดง
                        plt.plot(ref_t.iloc[sort_idx], ref_f.iloc[sort_idx],
                                 label=f'Ref: {species_name}',
                                 color='red', linestyle='--', linewidth=2, alpha=0.7)
                        found = True
                        break # เจอ 1 เส้นแล้วพอเลย

        plt.title(f"Prediction: {species_name}", fontsize=12)
        plt.xlabel("Temperature (°C)")
        plt.ylabel("Fluorescence (Diff)")
        plt.legend()
        plt.grid(True, linestyle=':', alpha=0.6)
        plt.tight_layout()

        # Convert to Base64
        buf = io.BytesIO()
        plt.savefig(buf, format='png', dpi=100)
        plt.close()
        buf.seek(0)
        img_str = base64.b64encode(buf.read()).decode('utf-8')
        return f"data:image/png;base64,{img_str}"

    except Exception as e:
        print(f"Plot Error: {e}")
        plt.close()
        return None

# ==========================================
# 3. API ENDPOINT
# ==========================================
@app.get("/")
def home():
    ref_status = "Loaded" if ref_df is not None else "Not Found (No Red Line)"
    return {"message": f"Orchid AI: Model Loaded, Ref Data: {ref_status}"}

@app.post("/predict")
async def predict(files: List[UploadFile] = File(...)):
    if not model_data:
        raise HTTPException(status_code=500, detail="Model file not found.")

    all_results = []

    try:
        for file in files:
            contents = await file.read()
            filename = file.filename.lower()

            try:
                if filename.endswith('.csv'):
                    df = pd.read_csv(io.BytesIO(contents))
                else:
                    df = pd.read_excel(io.BytesIO(contents))
            except:
                continue

            columns = df.columns.tolist()
            processed_pairs = set()

            def process_and_predict(t_arr, f_arr, sample_name):
                T_peak, F_peak, width, area = extract_peak_features(t_arr, f_arr)
                if not np.isnan(T_peak):
                    features_df = pd.DataFrame([[T_peak, F_peak, width, area]],
                                             columns=["T_peak", "F_peak", "Width_FWHM", "Area"])
                    pred_idx = model_data["model"].predict(features_df)[0]
                    species_name = model_data["label_encoder"].inverse_transform([pred_idx])[0]

                    # สร้างกราฟ (จะมีเส้นแดงถ้าเจอ Ref Data)
                    plot_image = generate_plot_base64(t_arr, f_arr, species_name)

                    return {
                        "filename": file.filename,
                        "sample_id": sample_name,
                        "T_peak": round(T_peak, 4),
                        "F_peak": round(F_peak, 4),
                        "Width_FWHM": round(width, 4),
                        "Area": round(area, 4),
                        "predicted_species": species_name,
                        "plot_image": plot_image
                    }
                return None

            if 'T' in columns and 'F' in columns:
                res = process_and_predict(
                    pd.to_numeric(df['T'], errors='coerce').values,
                    pd.to_numeric(df['F'], errors='coerce').values,
                    "Uploaded-Sample"
                )
                if res: all_results.append(res)

            for col in columns:
                m = re.match(r"^(.*)T(\d+)$", str(col))
                if m:
                    prefix, num = m.group(1), m.group(2)
                    f_col = f"{prefix}F{num}"
                    if f_col in columns and col not in processed_pairs:
                        processed_pairs.add(col)
                        res = process_and_predict(
                            pd.to_numeric(df[col], errors='coerce').values,
                            pd.to_numeric(df[f_col], errors='coerce').values,
                            f"{prefix}-{num}"
                        )
                        if res: all_results.append(res)

        if not all_results:
             return {"success": False, "message": "No valid data found."}

        return {"success": True, "results": all_results}

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == '__main__':
    port = int(os.environ.get('PORT', 8000))
    uvicorn.run(app, host='0.0.0.0', port=port)