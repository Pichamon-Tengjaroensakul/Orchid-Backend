# -*- coding: utf-8 -*-
"""web.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12w-zLfUrcKXiEDE-uvGpt7VtLst2_9e_
"""

from fastapi import FastAPI, UploadFile, File
from fastapi.middleware.cors import CORSMiddleware
import pandas as pd
import numpy as np
import joblib
import io
import traceback
import re
from collections import defaultdict

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/")
def home():
    return {"message": "Orchid API is running!"}

# --- 1. โหลดโมเดล (Decision Tree) ---
try:
    artifacts = joblib.load("orchid_decision_tree_v1.pkl")
    model = artifacts["model"]
    le = artifacts["label_encoder"]
    feat_cols = artifacts["feature_columns"]
    class_labels = model.classes_
    print("✅ Model loaded successfully.")
except Exception as e:
    print(f"❌ Model loading failed: {e}")
    model = None
    le = None

# --- 2. ฟังก์ชันสกัด Feature (เหมือนของเพื่อนคุณ) ---
def extract_peak_features(t, f):
    mask = ~np.isnan(t) & ~np.isnan(f)
    t = np.asarray(t[mask])
    f = np.asarray(f[mask])
    if len(t) < 3: return np.nan, np.nan, np.nan, np.nan

    sort_idx = np.argsort(t)
    t = t[sort_idx]
    f = f[sort_idx]

    peak_idx = np.argmax(f)
    F_peak = float(f[peak_idx])
    T_peak = float(t[peak_idx])

    # รองรับ numpy เวอร์ชันใหม่ (trapezoid) และเก่า (trapz)
    if hasattr(np, 'trapezoid'):
        area = float(np.trapezoid(f, x=t))
    else:
        area = float(np.trapz(f, t))

    half = F_peak / 2.0
    above_half = np.where(f >= half)[0]
    if len(above_half) >= 2:
        width = float(t[above_half[-1]] - t[above_half[0]])
    else:
        width = np.nan
    return T_peak, F_peak, width, area

# --- 3. ฟังก์ชันดึงชื่อกลุ่ม (ใช้ตรรกะเดียวกับ finish_model.py) ---
def get_species_group_name(col_name):
    # ใช้ Regex ดึงเฉพาะตัวอักษรภาษาอังกฤษข้างหน้า
    # เช่น "PtanalbaT1" -> "Ptanalba", "Csp015T3" -> "Csp"
    m = re.match(r"^([A-Za-z]+)", str(col_name))
    if m:
        return m.group(1)
    return "Unknown"

# --- 4. ฟังก์ชันหลัก: จัดกลุ่มและเตรียมข้อมูล ---
def process_file_and_group(df):
    columns = df.columns.tolist()
    all_features = []  # รวมฟีเจอร์ทั้งหมดจากทุกคอลัมน์

    # วนลูปจับคู่ T และ F
    for i in range(0, len(columns) - 1, 2):
        t_col = columns[i]
        f_col = columns[i+1]

        t_vals = pd.to_numeric(df[t_col], errors='coerce').values
        f_vals = pd.to_numeric(df[f_col], errors='coerce').values

        T_peak, F_peak, width, area = extract_peak_features(t_vals, f_vals)

        if not np.isnan(T_peak):
            all_features.append([T_peak, F_peak, width, area])

    return np.array(all_features)  # ส่งค่าเป็น Array 2D

@app.post("/predict")
async def predict(file: UploadFile = File(...)):
    try:
        if model is None:
            return {"results": []}

        contents = await file.read()
        df = pd.read_excel(io.BytesIO(contents))

        # 1. ดึงฟีเจอร์ทั้งหมดจากไฟล์ (รวมทุกคอลัมน์ T/F ที่มี)
        X_all = process_file_and_group(df)

        # ตรวจสอบว่ามีข้อมูลให้ทำนายหรือไม่
        if len(X_all) == 0:
            return {"results": []}

        # 2. ใช้โมเดลทำนายความน่าจะเป็นของทุกแถว
        probs_all = model.predict_proba(X_all)

        # 3. หาค่าเฉลี่ยของความน่าจะเป็นทั้งหมด (รวมทุกแถว)
        avg_probs = np.mean(probs_all, axis=0)

        # 4. หา Top 4 จากค่าเฉลี่ย
        top_indices = np.argsort(avg_probs)[::-1][:4]

        top_4_data = []
        max_score = 0.0

        for k, idx in enumerate(top_indices):
            pred_label_code = class_labels[idx]
            try:
                species_name = le.inverse_transform([pred_label_code])[0]
            except:
                species_name = "Unknown"

            score = int(round(avg_probs[idx] * 100))
            if k == 0:
                max_score = score

            if score >= 0:
                display_text = f"{k + 1}. {species_name} {score}%"
                top_4_data.append({
                    "rank": k + 1,
                    "species": display_text,
                    "confidence": score
                })

        # 5. ส่งผลลัพธ์เป็นรายการเดียว (ไม่แบ่งกลุ่ม)
        results = [{
            "filename": "",  # ใช้ค่าว่างเพื่อซ่อนชื่อไฟล์ใน UI หากต้องการ
            "group_real_name": "All Samples Combined",  # ระบุว่ารวมทุกอย่าง
            "top_4_details": top_4_data,
            "sort_score": max_score
        }]

        return {"results": results}

    except Exception as e:
        print(traceback.format_exc())
        return {"results": []}