# -*- coding: utf-8 -*-
"""web.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BL6rGfcjRjgT-hPDLiIJHgnvx2CM4R33
"""

from fastapi import FastAPI, UploadFile, File
from fastapi.middleware.cors import CORSMiddleware
import pandas as pd
import numpy as np
import joblib
import io
import traceback

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/")
def home():
    return {"message": "Orchid API is running!"}

# โหลดโมเดล
try:
    artifacts = joblib.load("orchid_decision_tree_v1.pkl")
    model = artifacts["model"]
    le = artifacts["label_encoder"]
    feat_cols = artifacts["feature_columns"]
    class_labels = model.classes_
    print("✅ Model loaded successfully.")
except Exception as e:
    print(f"❌ Model loading failed: {e}")
    model = None
    le = None

def extract_peak_features(t, f):
    # ตรวจสอบค่าว่าง
    mask = ~np.isnan(t) & ~np.isnan(f)
    t = np.asarray(t[mask])
    f = np.asarray(f[mask])
    if len(t) < 3: return np.nan, np.nan, np.nan, np.nan

    sort_idx = np.argsort(t)
    t = t[sort_idx]
    f = f[sort_idx]

    peak_idx = np.argmax(f)
    F_peak = float(f[peak_idx])
    T_peak = float(t[peak_idx])

    # --- จุดแก้บั๊ก (รองรับ NumPy ทุกเวอร์ชัน) ---
    # ถ้าเป็น NumPy รุ่นใหม่ (2.0+) จะใช้ trapezoid
    # ถ้าเป็น NumPy รุ่นเก่า จะใช้ trapz
    if hasattr(np, 'trapezoid'):
        area = float(np.trapezoid(f, x=t))
    else:
        area = float(np.trapz(f, t))
    # ----------------------------------------

    half = F_peak / 2.0
    above_half = np.where(f >= half)[0]
    if len(above_half) >= 2:
        width = float(t[above_half[-1]] - t[above_half[0]])
    else:
        width = np.nan
    return T_peak, F_peak, width, area

def process_file(df):
    columns = df.columns.tolist()
    features = []

    for i in range(0, len(columns) - 1, 2):
        t_col = columns[i]
        f_col = columns[i+1]
        t_vals = pd.to_numeric(df[t_col], errors='coerce').values
        f_vals = pd.to_numeric(df[f_col], errors='coerce').values
        T_peak, F_peak, width, area = extract_peak_features(t_vals, f_vals)
        if not np.isnan(T_peak):
            features.append({"T_peak": T_peak, "F_peak": F_peak, "Width_FWHM": width, "Area": area})
    return pd.DataFrame(features)

@app.post("/predict")
async def predict(file: UploadFile = File(...)):
    try:
        if model is None: return {"results": []}

        contents = await file.read()
        df = pd.read_excel(io.BytesIO(contents))
        processed_df = process_file(df)

        if processed_df.empty: return {"results": []}

        X = processed_df[feat_cols].to_numpy()
        probabilities = model.predict_proba(X)

        results = []
        for i in range(len(processed_df)):
            probs = probabilities[i]
            top_indices = np.argsort(probs)[::-1][:4]

            top_4_data = []
            max_score = 0.0

            for k, idx in enumerate(top_indices):
                pred_label_code = class_labels[idx]
                try:
                    species_name = le.inverse_transform([pred_label_code])[0]
                except:
                    species_name = f"Species {pred_label_code}"

                score = float(probs[idx] * 100)
                if k == 0: max_score = score

                if score > 0:
                    top_4_data.append({
                        "rank": k + 1,
                        "species": species_name,
                        "confidence": score
                    })

            results.append({
                "top_4_details": top_4_data,
                "sort_score": max_score
            })

        results.sort(key=lambda x: x["sort_score"], reverse=True)
        return {"results": results}

    except Exception as e:
        print(traceback.format_exc())
        return {"results": []}