# -*- coding: utf-8 -*-
"""web.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12w-zLfUrcKXiEDE-uvGpt7VtLst2_9e_
"""

from fastapi import FastAPI, UploadFile, File
from fastapi.middleware.cors import CORSMiddleware
import pandas as pd
import numpy as np
import joblib
import io
import traceback
import re
from collections import defaultdict

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/")
def home():
    return {"message": "Orchid API is running!"}

# --- โหลดโมเดล ---
try:
    artifacts = joblib.load("orchid_decision_tree_v1.pkl")
    model = artifacts["model"]
    le = artifacts["label_encoder"]
    feat_cols = artifacts["feature_columns"]
    class_labels = model.classes_
    print("✅ Model loaded successfully.")
except Exception as e:
    print(f"❌ Model loading failed: {e}")
    model = None
    le = None

def extract_peak_features(t, f):
    mask = ~np.isnan(t) & ~np.isnan(f)
    t = np.asarray(t[mask])
    f = np.asarray(f[mask])
    if len(t) < 3: return np.nan, np.nan, np.nan, np.nan

    sort_idx = np.argsort(t)
    t = t[sort_idx]
    f = f[sort_idx]

    peak_idx = np.argmax(f)
    F_peak = float(f[peak_idx])
    T_peak = float(t[peak_idx])

    if hasattr(np, 'trapezoid'):
        area = float(np.trapezoid(f, x=t))
    else:
        area = float(np.trapz(f, t))

    half = F_peak / 2.0
    above_half = np.where(f >= half)[0]
    if len(above_half) >= 2:
        width = float(t[above_half[-1]] - t[above_half[0]])
    else:
        width = np.nan
    return T_peak, F_peak, width, area

def get_species_name(col_name):
    # ใช้ Regex เดียวกับไฟล์ finish_model.py ของเพื่อนคุณ
    # คือเอาเฉพาะตัวอักษรภาษาอังกฤษข้างหน้า (เช่น Csp015 -> Csp)
    m = re.match(r"^([A-Za-z]+)", str(col_name))
    if m:
        return m.group(1)
    return "Unknown"

def process_file_and_group(df):
    columns = df.columns.tolist()
    grouped_data = defaultdict(list)

    for i in range(0, len(columns) - 1, 2):
        t_col = columns[i]
        f_col = columns[i+1]

        # จัดกลุ่มตามตรรกะโมเดลเพื่อนคุณ
        group_name = get_species_name(t_col)

        t_vals = pd.to_numeric(df[t_col], errors='coerce').values
        f_vals = pd.to_numeric(df[f_col], errors='coerce').values

        T_peak, F_peak, width, area = extract_peak_features(t_vals, f_vals)

        if not np.isnan(T_peak):
            grouped_data[group_name].append([T_peak, F_peak, width, area])

    return grouped_data

@app.post("/predict")
async def predict(file: UploadFile = File(...)):
    try:
        if model is None: return {"results": []}

        contents = await file.read()
        df = pd.read_excel(io.BytesIO(contents))

        # 1. จัดกลุ่มข้อมูล
        grouped_features = process_file_and_group(df)

        if not grouped_features: return {"results": []}

        results = []

        # 2. วิเคราะห์ทีละกลุ่ม
        for group_name, features_list in grouped_features.items():
            X_group = np.array(features_list)

            # ทำนายความน่าจะเป็นและหาค่าเฉลี่ย (Group Analysis)
            probs_group = model.predict_proba(X_group)
            avg_probs = np.mean(probs_group, axis=0)

            # เรียงจากมากไปน้อย (Descending)
            top_indices = np.argsort(avg_probs)[::-1][:4]

            top_4_data = []
            max_score = 0.0

            # สร้าง List ข้อความสำหรับส่งไปโชว์
            # เราฟอร์แมตข้อความที่นี่เลย เพื่อให้หน้าเว็บแสดงผลสวยโดยไม่ต้องแก้ Frontend
            for k, idx in enumerate(top_indices):
                pred_label_code = class_labels[idx]
                try:
                    species_name = le.inverse_transform([pred_label_code])[0]
                except:
                    species_name = "Unknown"

                score = int(round(avg_probs[idx] * 100)) # ปัดเศษเป็นจำนวนเต็ม
                if k == 0: max_score = score

                if score >= 0: # แสดงทุกอันดับแม้คะแนนน้อย
                    # จัดรูปแบบข้อความตรงนี้: "1. Ptanalba 70%"
                    display_text = f"{k + 1}. {species_name} {score}%"

                    top_4_data.append({
                        "rank": k + 1,
                        "species": display_text, # ส่งข้อความที่จัดแล้วไปในช่องชื่อเลย
                        "confidence": score
                    })

            results.append({
                # ส่งค่าว่างไปที่ filename เพื่อซ่อนชื่อกลุ่ม (เพราะแก้ Frontend ไม่ได้)
                "filename": "",
                "group_real_name": group_name, # เผื่อไว้ใช้ debug
                "top_4_details": top_4_data,
                "sort_score": max_score
            })

        # เรียงลำดับบรรทัดตามความมั่นใจสูงสุด
        results.sort(key=lambda x: x["sort_score"], reverse=True)
        return {"results": results}

    except Exception as e:
        print(traceback.format_exc())
        return {"results": []}