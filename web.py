# -*- coding: utf-8 -*-
"""web.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jJKSdq8rTp3n7Qx3NYIkaOAjJ8xovQzW
"""

from fastapi import FastAPI, File, UploadFile, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from typing import List
import uvicorn
import pandas as pd
import numpy as np
import joblib
import os
import re
import io
import base64
import matplotlib
matplotlib.use('Agg') # ใช้ Backend แบบไม่แสดงหน้าต่าง (สำหรับ Server)
import matplotlib.pyplot as plt

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ==========================================
# 1. โหลดโมเดล และ ข้อมูลอ้างอิง (Reference Data)
# ==========================================
MODEL_FILENAME = 'orchid_decision_tree_v1.pkl'
REF_DATA_FILENAME = 'PROJECT_DATA.xlsx' # ⚠️ ต้องมีไฟล์นี้ใน GitHub

MODEL_PATH = os.path.join(os.path.dirname(__file__), MODEL_FILENAME)
REF_PATH = os.path.join(os.path.dirname(__file__), REF_DATA_FILENAME)

model_data = None
ref_df = None

# โหลดโมเดล
try:
    if os.path.exists(MODEL_PATH):
        model_data = joblib.load(MODEL_PATH)
        print(f"✅ Model Loaded: {MODEL_FILENAME}")
    else:
        print(f"❌ Model Not Found: {MODEL_PATH}")
except Exception as e:
    print(f"❌ Error loading model: {e}")

# โหลดไฟล์ข้อมูลอ้างอิง (PROJECT_DATA)
try:
    if os.path.exists(REF_PATH):
        if REF_PATH.endswith('.csv'):
            ref_df = pd.read_csv(REF_PATH)
        else:
            ref_df = pd.read_excel(REF_PATH)
        print(f"✅ Reference Data Loaded: {REF_DATA_FILENAME}")
    else:
        print(f"⚠️ Reference Data Not Found (Graph will have no reference line)")
except Exception as e:
    print(f"⚠️ Error loading reference data: {e}")

# ==========================================
# 2. ฟังก์ชันคำนวณ Feature & Helper
# ==========================================
def extract_peak_features(t, f):
    try:
        mask = ~np.isnan(t) & ~np.isnan(f)
        t, f = np.asarray(t[mask]), np.asarray(f[mask])
        if len(t) < 3: return np.nan, np.nan, np.nan, np.nan

        sort_idx = np.argsort(t)
        t, f = t[sort_idx], f[sort_idx]

        peak_idx = np.argmax(f)
        F_peak = float(f[peak_idx])
        T_peak = float(t[peak_idx])

        if hasattr(np, 'trapezoid'): area = float(np.trapezoid(f, x=t))
        else: area = float(np.trapz(f, t))

        half = F_peak / 2.0
        above_half = np.where(f >= half)[0]
        if len(above_half) >= 2:
            width = float(t[above_half[-1]] - t[above_half[0]])
        else: width = np.nan

        return T_peak, F_peak, width, area
    except:
        return np.nan, np.nan, np.nan, np.nan

# ฟังก์ชันวาดกราฟและแปลงเป็น Base64
def generate_plot_base64(user_t, user_f, species_name):
    try:
        plt.figure(figsize=(6, 4))

        # 1. พล็อตเส้นของผู้ใช้ (User Data)
        plt.plot(user_t, user_f, label='Your Sample', color='blue', linewidth=2)

        # 2. พล็อตเส้นอ้างอิง (Reference) จาก PROJECT_DATA
        if ref_df is not None and species_name != "Unknown":
            # พยายามหาคอลัมน์ที่ชื่อใกล้เคียงกับสายพันธุ์ที่ทำนายได้
            # เช่น ทำนายได้ "Ptanalba" -> หาคอลัมน์ที่ขึ้นต้นด้วย "PtanalbaT..."
            found_ref = False
            cols = ref_df.columns

            # Logic การหาคู่ T, F ของสายพันธุ์นั้น (เอาอันแรกที่เจอมาเป็น Ref)
            for col in cols:
                # ตรวจสอบว่าคอลัมน์เริ่มด้วยชื่อสายพันธุ์ และจบด้วย T ตามด้วยตัวเลข
                # เราจะตัดคำว่า 'sp' หรือตัวอักษรท้ายๆ ออกนิดหน่อยเพื่อให้ match ง่ายขึ้น
                search_key = species_name.split(' ')[0] # เอาแค่ชื่อแรก

                if search_key in str(col) and 'T' in str(col):
                    # หาคู่ F ของมัน
                    prefix = str(col).split('T')[0] # เช่น Ptanalba
                    suffix = str(col).split('T')[-1] # เช่น 1
                    f_col_candidate = f"{prefix}F{suffix}"

                    if f_col_candidate in cols:
                        ref_t = pd.to_numeric(ref_df[col], errors='coerce').dropna()
                        ref_f = pd.to_numeric(ref_df[f_col_candidate], errors='coerce').dropna()

                        # ต้อง sort T ก่อน plot
                        sort_idx = np.argsort(ref_t)
                        plt.plot(ref_t.iloc[sort_idx], ref_f.iloc[sort_idx],
                                 label=f'Ref: {species_name}',
                                 color='red', linestyle='--', alpha=0.7)
                        found_ref = True
                        break # เจอเส้นนึงแล้ว พอเลย

        plt.title(f"Comparison: Your Sample vs {species_name}")
        plt.xlabel("Temperature (T)")
        plt.ylabel("Fluorescence (F)")
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.tight_layout()

        # Save to buffer
        buf = io.BytesIO()
        plt.savefig(buf, format='png', dpi=100)
        plt.close()
        buf.seek(0)
        img_str = base64.b64encode(buf.read()).decode('utf-8')
        return f"data:image/png;base64,{img_str}"

    except Exception as e:
        print(f"Plot Error: {e}")
        plt.close()
        return None

# ==========================================
# 3. API Endpoints
# ==========================================
@app.get("/")
def home():
    status = "พร้อมใช้งาน (Graph Plotting Enabled)"
    return {"message": f"Orchid AI Backend: {status}"}

@app.post("/predict")
async def predict(files: List[UploadFile] = File(...)):
    if not model_data:
        raise HTTPException(status_code=500, detail="Model not found.")

    all_results = []

    try:
        for file in files:
            contents = await file.read()
            filename = file.filename.lower()

            try:
                if filename.endswith('.csv'):
                    df = pd.read_csv(io.BytesIO(contents))
                else:
                    df = pd.read_excel(io.BytesIO(contents))
            except:
                continue

            columns = df.columns.tolist()
            processed_pairs = set()

            def process_and_predict(t_arr, f_arr, sample_name):
                T_peak, F_peak, width, area = extract_peak_features(t_arr, f_arr)
                if not np.isnan(T_peak):
                    features_df = pd.DataFrame([[T_peak, F_peak, width, area]],
                                             columns=["T_peak", "F_peak", "Width_FWHM", "Area"])
                    pred_idx = model_data["model"].predict(features_df)[0]
                    species_name = model_data["label_encoder"].inverse_transform([pred_idx])[0]

                    # ✅ สร้างกราฟ (Base64 Image)
                    plot_image = generate_plot_base64(t_arr, f_arr, species_name)

                    return {
                        "filename": file.filename,
                        "sample_id": sample_name,
                        "T_peak": round(T_peak, 4),
                        "F_peak": round(F_peak, 4),
                        "Width_FWHM": round(width, 4),
                        "Area": round(area, 4),
                        "predicted_species": species_name,
                        "plot_image": plot_image # ส่งรูปกลับไปให้ Frontend
                    }
                return None

            if 'T' in columns and 'F' in columns:
                res = process_and_predict(
                    pd.to_numeric(df['T'], errors='coerce').values,
                    pd.to_numeric(df['F'], errors='coerce').values,
                    "Uploaded-Sample"
                )
                if res: all_results.append(res)

            for col in columns:
                m = re.match(r"^(.*)T(\d+)$", str(col))
                if m:
                    prefix, num = m.group(1), m.group(2)
                    f_col = f"{prefix}F{num}"
                    if f_col in columns and col not in processed_pairs:
                        processed_pairs.add(col)
                        res = process_and_predict(
                            pd.to_numeric(df[col], errors='coerce').values,
                            pd.to_numeric(df[f_col], errors='coerce').values,
                            f"{prefix}-{num}"
                        )
                        if res: all_results.append(res)

        if not all_results:
             return {"success": False, "message": "No valid data found."}

        return {"success": True, "results": all_results}

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == '__main__':
    port = int(os.environ.get('PORT', 8000))
    uvicorn.run(app, host='0.0.0.0', port=port)