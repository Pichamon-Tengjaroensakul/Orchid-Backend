# -*- coding: utf-8 -*-
"""web.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jJKSdq8rTp3n7Qx3NYIkaOAjJ8xovQzW
"""

from fastapi import FastAPI, File, UploadFile, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from typing import List
import uvicorn
import pandas as pd
import numpy as np
import joblib
import os
import re
import io
import base64
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# =========================================================
# üîß ‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏ö‡∏Ñ‡∏π‡πà (MANUAL MAPPING) - ‡πÅ‡∏Å‡πâ‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ!
# =========================================================
# ‡πÉ‡∏™‡πà‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏¢‡∏û‡∏±‡∏ô‡∏ò‡∏∏‡πå‡∏ó‡∏µ‡πà‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏≤‡∏¢‡πÑ‡∏î‡πâ‡∏ó‡∏≤‡∏á‡∏ã‡πâ‡∏≤‡∏¢ : ‡πÉ‡∏™‡πà‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå T ‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå PROJECT_DATA ‡∏ó‡∏≤‡∏á‡∏Ç‡∏ß‡∏≤
# (‡∏ñ‡πâ‡∏≤‡πÄ‡∏™‡πâ‡∏ô‡πÅ‡∏î‡∏á‡πÑ‡∏°‡πà‡∏Ç‡∏∂‡πâ‡∏ô ‡πÉ‡∏´‡πâ‡∏°‡∏≤‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ä‡∏∑‡πà‡∏≠‡πÉ‡∏ô‡∏ô‡∏µ‡πâ‡∏Ñ‡∏£‡∏±‡∏ö)
SPECIES_MAPPING = {
    # "‡∏ä‡∏∑‡πà‡∏≠‡∏à‡∏≤‡∏Å AI": "‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÉ‡∏ô Excel"
    "Ptanalba": "PtanalbaT1",
    "PtanalbaT": "PtanalbaT1",
    "Ptan": "PtanT1",
    "PtanT": "PtanT1",
    "Ptak": "PtakT1",
    "PtakT": "PtakT1",
    "Pmis": "PmisT2",
    "PmisT": "PmisT2",
    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏π‡πà‡πÉ‡∏´‡∏°‡πà‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ‡πÑ‡∏î‡πâ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏¢‡πÜ...
}

# ==========================================
# 1. SETUP & LOAD DATA
# ==========================================
MODEL_FILENAME = 'orchid_decision_tree_v1.pkl'
REF_DATA_FILENAME = 'PROJECT_DATA.xlsx'

MODEL_PATH = os.path.join(os.path.dirname(__file__), MODEL_FILENAME)
REF_PATH = os.path.join(os.path.dirname(__file__), REF_DATA_FILENAME)

model_data = None
ref_df = None

# ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•
try:
    if os.path.exists(MODEL_PATH):
        model_data = joblib.load(MODEL_PATH)
        print(f"‚úÖ Model Loaded Successfully")
    else:
        print(f"‚ùå Model Not Found at {MODEL_PATH}")
except Exception as e:
    print(f"‚ùå Error loading model: {e}")

# ‡πÇ‡∏´‡∏•‡∏î Reference Data
try:
    if os.path.exists(REF_PATH):
        # ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå (‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á csv ‡πÅ‡∏•‡∏∞ excel)
        try:
            if REF_DATA_FILENAME.endswith('.csv'):
                ref_df = pd.read_csv(REF_PATH)
            else:
                ref_df = pd.read_excel(REF_PATH)
        except:
            ref_df = pd.read_excel(REF_PATH)

        # ‡∏•‡∏ö‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á‡∏´‡∏±‡∏ß‡∏ó‡πâ‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå
        ref_df.columns = ref_df.columns.str.strip()
        print(f"‚úÖ Reference Data Loaded: {len(ref_df)} rows")
    else:
        print(f"‚ö†Ô∏è Reference Data Not Found! (Reference line will not show)")
except Exception as e:
    print(f"‚ö†Ô∏è Error loading reference data: {e}")

# ==========================================
# 2. HELPER FUNCTIONS
# ==========================================
def extract_peak_features(t, f):
    try:
        mask = ~np.isnan(t) & ~np.isnan(f)
        t, f = np.asarray(t[mask]), np.asarray(f[mask])
        if len(t) < 3: return np.nan, np.nan, np.nan, np.nan

        sort_idx = np.argsort(t)
        t, f = t[sort_idx], f[sort_idx]

        peak_idx = np.argmax(f)
        F_peak = float(f[peak_idx])
        T_peak = float(t[peak_idx])

        if hasattr(np, 'trapezoid'): area = float(np.trapezoid(f, x=t))
        else: area = float(np.trapz(f, t))

        half = F_peak / 2.0
        above_half = np.where(f >= half)[0]
        if len(above_half) >= 2:
            width = float(t[above_half[-1]] - t[above_half[0]])
        else: width = np.nan

        return T_peak, F_peak, width, area
    except:
        return np.nan, np.nan, np.nan, np.nan

def generate_plot_base64(user_t, user_f, species_name):
    try:
        plt.figure(figsize=(8, 5))

        # 1. ‡∏ß‡∏≤‡∏î‡πÄ‡∏™‡πâ‡∏ô User (‡∏™‡∏µ‡∏ô‡πâ‡∏≥‡πÄ‡∏á‡∏¥‡∏ô)
        plt.plot(user_t, user_f, label='Your Sample', color='#0066cc', linewidth=2)

        # 2. ‡∏ß‡∏≤‡∏î‡πÄ‡∏™‡πâ‡∏ô Reference (‡∏™‡∏µ‡πÅ‡∏î‡∏á)
        if ref_df is not None and species_name != "Unknown":
            target_t_col = None

            # --- ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 1: ‡∏´‡∏≤‡∏à‡∏≤‡∏Å Manual Mapping ‡∏Å‡πà‡∏≠‡∏ô (‡∏ä‡∏±‡∏ß‡∏£‡πå‡∏™‡∏∏‡∏î) ---
            # ‡∏ï‡∏±‡∏î‡∏Ñ‡∏≥‡∏ß‡πà‡∏≤ sp ‡∏´‡∏£‡∏∑‡∏≠‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á‡∏≠‡∏≠‡∏Å‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö
            clean_key = species_name.replace('sp', '').strip()

            if species_name in SPECIES_MAPPING:
                target_t_col = SPECIES_MAPPING[species_name]
                print(f"‚úÖ Found in Mapping: {species_name} -> {target_t_col}")
            elif clean_key in SPECIES_MAPPING:
                target_t_col = SPECIES_MAPPING[clean_key]
                print(f"‚úÖ Found in Mapping (Cleaned): {clean_key} -> {target_t_col}")

            # --- ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 2: ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡πÉ‡∏ô Map ‡πÉ‡∏´‡πâ‡∏•‡∏≠‡∏á Auto Search ---
            if not target_t_col:
                print(f"‚ö†Ô∏è Not in map, trying auto-search for: {clean_key}")
                cols = list(ref_df.columns)
                # Regex: ‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏¢‡∏û‡∏±‡∏ô‡∏ò‡∏∏‡πå + T + ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç (Case Insensitive)
                pattern = re.compile(f"^{re.escape(clean_key)}T\\d+$", re.IGNORECASE)

                matches = [c for c in cols if pattern.match(c)]
                # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏à‡∏≠ T1 ‡πÄ‡∏≠‡∏≤ T1 ‡∏Å‡πà‡∏≠‡∏ô, ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÄ‡∏≠‡∏≤‡∏≠‡∏±‡∏ô‡πÅ‡∏£‡∏Å
                t1_match = next((m for m in matches if m.lower().endswith('t1')), None)
                if t1_match: target_t_col = t1_match
                elif matches: target_t_col = matches[0]

            # --- ‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≤‡∏ü ---
            if target_t_col and target_t_col in ref_df.columns:
                # ‡∏´‡∏≤‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå F ‡∏Ñ‡∏π‡πà‡∏Å‡∏±‡∏ô (‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô T ‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡πÄ‡∏õ‡πá‡∏ô F)
                last_t_idx = target_t_col.lower().rfind('t')
                target_f_col_upper = target_t_col[:last_t_idx] + 'F' + target_t_col[last_t_idx+1:]
                target_f_col_lower = target_t_col[:last_t_idx] + 'f' + target_t_col[last_t_idx+1:]

                target_f_col = None
                if target_f_col_upper in ref_df.columns: target_f_col = target_f_col_upper
                elif target_f_col_lower in ref_df.columns: target_f_col = target_f_col_lower

                if target_f_col:
                    print(f"   Plotting Ref: {target_t_col} & {target_f_col}")
                    ref_t = pd.to_numeric(ref_df[target_t_col], errors='coerce')
                    ref_f = pd.to_numeric(ref_df[target_f_col], errors='coerce')

                    mask = ~np.isnan(ref_t) & ~np.isnan(ref_f)
                    ref_t, ref_f = ref_t[mask], ref_f[mask]
                    sort_idx = np.argsort(ref_t)

                    plt.plot(ref_t.iloc[sort_idx], ref_f.iloc[sort_idx],
                             label=f'Ref: {species_name}',
                             color='#ff3333', linestyle='--', linewidth=2, alpha=0.8)
                else:
                    print(f"‚ùå Found T col {target_t_col} but F col missing.")
            else:
                print(f"‚ùå No matching column found for {species_name}")

        plt.title(f"Comparison: {species_name}", fontsize=14)
        plt.xlabel("Temperature (¬∞C)")
        plt.ylabel("Fluorescence (Diff)")
        plt.legend()
        plt.grid(True, linestyle=':', alpha=0.6)
        plt.tight_layout()

        buf = io.BytesIO()
        plt.savefig(buf, format='png', dpi=100)
        plt.close()
        buf.seek(0)
        img_str = base64.b64encode(buf.read()).decode('utf-8')
        return f"data:image/png;base64,{img_str}"

    except Exception as e:
        print(f"Plot Error: {e}")
        plt.close()
        return None

# ==========================================
# 3. API ENDPOINTS
# ==========================================
@app.get("/")
def home():
    ref_status = "Loaded" if ref_df is not None else "Not Found"
    return {"message": f"Orchid AI Ready. Ref Data: {ref_status}"}

@app.post("/predict")
async def predict(files: List[UploadFile] = File(...)):
    if not model_data:
        raise HTTPException(status_code=500, detail="Model file not found.")

    all_results = []

    try:
        for file in files:
            contents = await file.read()
            filename = file.filename.lower()
            try:
                if filename.endswith('.csv'):
                    df = pd.read_csv(io.BytesIO(contents))
                else:
                    df = pd.read_excel(io.BytesIO(contents))
            except:
                continue

            columns = df.columns.tolist()
            processed_pairs = set()

            def process_and_predict(t_arr, f_arr, sample_name):
                T_peak, F_peak, width, area = extract_peak_features(t_arr, f_arr)
                if not np.isnan(T_peak):
                    features_df = pd.DataFrame([[T_peak, F_peak, width, area]],
                                             columns=["T_peak", "F_peak", "Width_FWHM", "Area"])

                    pred_idx = model_data["model"].predict(features_df)[0]
                    species_name = model_data["label_encoder"].inverse_transform([pred_idx])[0]

                    probabilities = model_data["model"].predict_proba(features_df)[0]
                    confidence = round(probabilities[pred_idx] * 100, 2)

                    plot_image = generate_plot_base64(t_arr, f_arr, species_name)

                    return {
                        "filename": file.filename,
                        "sample_id": sample_name,
                        "T_peak": round(T_peak, 4),
                        "F_peak": round(F_peak, 4),
                        "Width_FWHM": round(width, 4),
                        "Area": round(area, 4),
                        "predicted_species": species_name,
                        "confidence_score": f"{confidence}%",
                        "plot_image": plot_image
                    }
                return None

            if 'T' in columns and 'F' in columns:
                res = process_and_predict(
                    pd.to_numeric(df['T'], errors='coerce').values,
                    pd.to_numeric(df['F'], errors='coerce').values,
                    "Uploaded-Sample"
                )
                if res: all_results.append(res)

            for col in columns:
                m = re.match(r"^(.*)T(\d+)$", str(col))
                if m:
                    prefix, num = m.group(1), m.group(2)
                    f_col = f"{prefix}F{num}"
                    if f_col in columns and col not in processed_pairs:
                        processed_pairs.add(col)
                        res = process_and_predict(
                            pd.to_numeric(df[col], errors='coerce').values,
                            pd.to_numeric(df[f_col], errors='coerce').values,
                            f"{prefix}-{num}"
                        )
                        if res: all_results.append(res)

        if not all_results:
             return {"success": False, "message": "No valid data found."}

        return {"success": True, "results": all_results}

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == '__main__':
    port = int(os.environ.get('PORT', 8000))
    uvicorn.run(app, host='0.0.0.0', port=port)