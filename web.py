# -*- coding: utf-8 -*-
"""web.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BL6rGfcjRjgT-hPDLiIJHgnvx2CM4R33
"""

from fastapi import FastAPI, UploadFile, File
from fastapi.middleware.cors import CORSMiddleware
import pandas as pd
import numpy as np
import joblib
import re
import io

app = FastAPI()

# --- 1. ตั้งค่า CORS (เปิดประตูให้ Vercel เข้ามาได้) ---
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # อนุญาตทุกเว็บ
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- 2. โหลดโมเดล AI ---
artifacts = joblib.load("orchid_decision_tree_v1.pkl")
model = artifacts["model"]
le = artifacts["label_encoder"]
medians = artifacts["medians"]
feat_cols = artifacts["feature_columns"]

# --- 3. สูตรคณิตศาสตร์ของเพื่อนคุณ (ห้ามแก้) ---
def extract_peak_features(t, f):
    mask = ~np.isnan(t) & ~np.isnan(f)
    t = np.asarray(t[mask])
    f = np.asarray(f[mask])

    if len(t) < 3:
        return np.nan, np.nan, np.nan, np.nan

    sort_idx = np.argsort(t)
    t = t[sort_idx]
    f = f[sort_idx]

    peak_idx = np.argmax(f)
    F_peak = float(f[peak_idx])
    T_peak = float(t[peak_idx])
    area = float(np.trapz(f, t))

    half = F_peak / 2.0
    above_half = np.where(f >= half)[0]
    if len(above_half) >= 2:
        width = float(t[above_half[-1]] - t[above_half[0]])
    else:
        width = np.nan

    return T_peak, F_peak, width, area

# --- 4. ฟังก์ชันเตรียมข้อมูล (เหมือนโค้ดเพื่อน แต่ปรับให้รับไฟล์ Excel ใหม่ได้) ---
def process_file(df):
    columns = df.columns.tolist()
    pairs = []

    # จับคู่คอลัมน์ T และ F
    for col in columns:
        m = re.match(r"^(.*)T(\d+)$", col)
        if m:
            prefix, rep = m.group(1), m.group(2)
            t_col = col
            f_col = f"{prefix}F{rep}"

            # ถ้ามีคู่ F อยู่จริง ให้เก็บไว้
            if f_col in columns:
                pairs.append((t_col, f_col))

    features = []
    for t_col, f_col in pairs:
        t_vals = df[t_col].values
        f_vals = df[f_col].values

        # เรียกใช้สูตรคำนวณ
        T_peak, F_peak, width, area = extract_peak_features(t_vals, f_vals)

        features.append({
            "sample_id": t_col,
            "T_peak": T_peak,
            "F_peak": F_peak,
            "Width_FWHM": width,
            "Area": area
        })

    feat_df = pd.DataFrame(features)

    if feat_df.empty:
        return feat_df

    # แทนค่าที่หายไปด้วยค่า Median (ใช้ค่าเดียวกับตอนเทรน)
    for col in feat_cols:
        feat_df[col] = feat_df[col].astype(float)
        if col in medians:
             feat_df[col] = feat_df[col].fillna(medians[col])

    return feat_df

# --- 5. ส่วนรับคำสั่งจากหน้าเว็บ ---
@app.post("/predict")
async def predict(file: UploadFile = File(...)):
    try:
        # อ่านไฟล์ Excel
        contents = await file.read()
        df = pd.read_excel(io.BytesIO(contents))

        # แปลงข้อมูล
        processed_df = process_file(df)

        if processed_df.empty:
            return {"error": "ไม่พบคู่ข้อมูล T/F ในไฟล์ Excel กรุณาตรวจสอบรูปแบบไฟล์"}

        # เตรียมข้อมูลเข้าโมเดล
        X = processed_df[feat_cols].to_numpy()

        # ให้ AI ทำนาย
        predictions = model.predict(X)
        probabilities = model.predict_proba(X)

        # จัดรูปแบบผลลัพธ์ส่งกลับไปหน้าเว็บ
        results = []
        for i, pred_idx in enumerate(predictions):
            species_name = le.inverse_transform([pred_idx])[0]
            confidence = float(np.max(probabilities[i]))

            # แปลงเป็น %
            confidence_percent = round(confidence * 100, 2)

            results.append({
                "sample_id": processed_df.iloc[i]["sample_id"],
                "species": species_name,
                "confidence": confidence_percent
            })

        return {"results": results}

    except Exception as e:
        return {"error": f"Server Error: {str(e)}"}